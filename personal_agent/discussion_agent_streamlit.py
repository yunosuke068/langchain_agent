from langchain_openai import ChatOpenAI, AzureChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.prompts import HumanMessagePromptTemplate
from langchain_core.messages import SystemMessage
from langchain.chains.llm import LLMChain
import os, json
from datetime import datetime
import streamlit as st
import traceback
import logging

# ã‚­ãƒ£ãƒ©è¨­å®š
character_defs = {
    "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆA": "ã‚ãªãŸã¯å†·é™ã§è«–ç†çš„ãªæ€è€ƒã‚’å¾—æ„ã¨ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚ã‚ã‚‰ã‚†ã‚‹ä¸»å¼µã«å¯¾ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚„äº‹å®Ÿã€å› æœé–¢ä¿‚ã«åŸºã¥ã„ãŸèª¬æ˜ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚æ„Ÿæƒ…çš„ãªä¸»å¼µã‚„ç›´æ„Ÿã ã‘ã®æ„è¦‹ã«ã¯æ…é‡ã§ã€ç†è«–çš„ãªè£ä»˜ã‘ãŒã‚ã‚‹ã‹ã‚’é‡è¦–ã—ã¦ãã ã•ã„ã€‚å£èª¿ã¯ã‚„ã‚„ç¡¬ã‚ã§ä¸å¯§ã€‚è­°è«–ã§ã¯å†·é™ã‹ã¤ä¸€è²«æ€§ã‚’æŒã£ã¦æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ã€‚",
    "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆB": "ã‚ãªãŸã¯ä»–äººã®æ„Ÿæƒ…ã‚„å¿ƒã®å‹•ãã«æ•æ„Ÿãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚è­°è«–ã®ä¸­ã§ã‚‚ã€ç™ºè¨€è€…ã®æ°—æŒã¡ã‚„ç«‹å ´ã«å¯„ã‚Šæ·»ã†ã“ã¨ã‚’é‡è¦–ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚ã€ã©ã†æ„Ÿã˜ã‚‹ã‹ã€ã€äººã¨ã—ã¦ã©ã†ã‹ã€ã¨ã„ã†è¦³ç‚¹ã§è©±ã™å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚å£èª¿ã¯ã‚„ã‚ã‚‰ã‹ãã€è¦ªã—ã¿ã‚„ã™ã„é›°å›²æ°—ã§è©±ã—ã¦ãã ã•ã„ã€‚",
    "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆC": "ã‚ãªãŸã¯ç–‘ã„æ·±ãã€è­°è«–ã®ä¸­ã§ä»–ã®æ„è¦‹ã«å¯¾ã—ã¦ç‡ç›´ã«ãƒ„ãƒƒã‚³ãƒŸã‚’å…¥ã‚Œã‚‹ã‚¿ã‚¤ãƒ—ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚å¸¸ã«ã€ãã‚Œã¯æœ¬å½“ã‹ï¼Ÿã€ã€ä»–ã®è¦‹æ–¹ã¯ãªã„ã‹ï¼Ÿã€ã¨å•ã„ç›´ã™å§¿å‹¢ã‚’æŒã£ã¦ã„ã¾ã™ã€‚æ™‚ã«ã¯çš®è‚‰ã‚’äº¤ãˆãªãŒã‚‰ã‚‚ã€çš„ç¢ºã«å•é¡Œç‚¹ã‚’çªãã“ã¨ãŒå¾—æ„ã§ã™ã€‚å£èª¿ã¯ã‚„ã‚„ãã¤ã‚ã§ã‚ºãƒã‚ºãƒè¨€ã„ã¾ã™ãŒã€å†·é™ã•ã¯å¤±ã„ã¾ã›ã‚“ã€‚",
    "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆD": "ã‚ãªãŸã¯è‡ªç”±ãªç™ºæƒ³ã¨ç‹¬å‰µçš„ãªã‚¢ã‚¤ãƒ‡ã‚¢ã‚’é‡è¦–ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚å¸¸è­˜ã«ã¨ã‚‰ã‚ã‚Œãšã€çªæ‹å­ã‚‚ãªã„æ„è¦‹ã§ã‚‚æã‚Œãšã«ææ¡ˆã—ã¾ã™ã€‚è­°è«–ã§ã¯ã€ã“ã†ã„ã†è€ƒãˆæ–¹ã‚‚ã§ãã‚‹ã‹ã‚‚ï¼ã€ã¨ã„ã£ãŸã‚¹ã‚¿ãƒ³ã‚¹ã§ã€é›°å›²æ°—ã‚’æ˜ã‚‹ãã—ã€æµã‚Œã‚’å¤‰ãˆã‚‹å½¹å‰²ã‚‚æ‹…ã„ã¾ã™ã€‚å£èª¿ã¯è»½ã‚„ã‹ã§æ¥½ã—ã’ã€ã‚„ã‚„ãƒã‚¤ãƒšãƒ¼ã‚¹ã§ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚"
}

# ãƒ¢ãƒ‡ãƒ«å®šç¾©
llm = AzureChatOpenAI(
    openai_api_version="2023-05-15",
    deployment_name="gpt-4o",
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    openai_api_key=os.getenv("AZURE_OPENAI_API_KEY"),
)

# å„å­ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒã‚§ãƒ¼ãƒ³ç”Ÿæˆ
def create_child_agent_chain(llm, character_defs):
    agents = {}
    for name, persona in character_defs.items():
        prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content=f'ã‚ãªãŸã¯{name}ã¨ã„ã†åå‰ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚ä¼šè©±å±¥æ­´ã‚’è€ƒæ…®ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã ã‘ã§ãªãã€ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ„è¦‹ã«ã‚‚åå¿œã—ãŸã‚Šè­°è«–ã™ã‚‹ã“ã¨ã‚’å¿ƒæ›ã‘ã¦ãã ã•ã„ã€‚\nå‡ºåŠ›å½¢å¼ã¯{{"name": "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå", "content": "ç™ºè¨€å†…å®¹"}}ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n\næ€§æ ¼:\n{persona}'),
            MessagesPlaceholder(variable_name="chat_history"),
            # HumanMessagePromptTemplate.from_template("{input}"),
        ])
        agents[name] = LLMChain(llm=llm, prompt=prompt, verbose=False)
    return agents

# ãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ï¼ˆè­°é•·ï¼‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®šç¾©
def create_facilitator_agent_chain(llm, chilsd_agent_names: list[str]):
    facilitator_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=f"ã‚ãªãŸã¯ãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç™ºè¨€å±¥æ­´ã‚’ã‚‚ã¨ã«ã€æ¬¡ã«ç™ºè¨€ã™ã¹ãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆ{'/'.join(chilsd_agent_names)}ï¼‰ã®åå‰ã ã‘ã‚’1ã¤è¿”ç­”ã—ã¦ãã ã•ã„ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç™ºè¨€å±¥æ­´ã‚’è€ƒæ…®ã—ã€å‡ç­‰ã«ç™ºè¨€ã§ãã‚‹ã‚ˆã†ã«æŒ¯ã‚Šåˆ†ã‘ã¦ãã ã•ã„ã€‚"),
        HumanMessagePromptTemplate.from_template("# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•\n{input}\n\n# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç™ºè¨€å±¥æ­´\n{agent_history}"),
    ])
    facilitator_chain = LLMChain(llm=llm, prompt=facilitator_prompt)
    return facilitator_chain

# ã‚µãƒãƒªãƒ¼ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
def create_summary_agent_chain(llm):
    summary_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="ä»¥ä¸‹ã®ä¼šè©±å±¥æ­´ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚å¿…è¦ãªã‚‰çµè«–ã‚’å‡ºã—ã¦ãã ã•ã„ã€‚"),
        MessagesPlaceholder(variable_name="chat_history"),
        HumanMessagePromptTemplate.from_template("{input}")
    ])
    summary_chain = LLMChain(llm=llm, prompt=summary_prompt)
    return summary_chain

# ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«å±¥æ­´ã‚’å‡ºåŠ›
def log_chat(log_path, role, name, content):
    with open(log_path, "a", encoding="utf-8") as f:
        f.write(f"{role.upper()} ({name}): {content}\n")
        f.write("-" * 50 + "\n")

# --- Streamlit UI ---
st.set_page_config(page_title="ãƒãƒ«ãƒã‚­ãƒ£ãƒ©ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ£ãƒƒãƒˆ", layout="wide")
st.title("ğŸ­ ãƒãƒ«ãƒã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒãƒ£ãƒƒãƒˆ")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "agent_history" not in st.session_state:
    st.session_state.agent_history = []
if "display_chat_history" not in st.session_state:
    st.session_state.display_chat_history = []
if "agents" not in st.session_state:
    st.session_state.agents = create_child_agent_chain(llm, character_defs)
if "facilitator" not in st.session_state:
    st.session_state.facilitator = create_facilitator_agent_chain(llm, list(character_defs.keys()))

# å…¥åŠ›æ¬„
user_input = st.chat_input("ã‚ãªãŸã®è³ªå•ã‚’å…¥åŠ›...")

# éå»ã®ä¼šè©±ã‚’è¡¨ç¤º
for msg in st.session_state.display_chat_history:
    with st.chat_message(msg.get("name", msg["role"])):
        st.markdown(msg["content"])

if user_input:
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    st.session_state.display_chat_history.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    st.session_state.agent_history = []  # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç™ºè¨€å±¥æ­´ã‚’åˆæœŸåŒ–

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç™ºè¨€ã‚¿ãƒ¼ãƒ³æ•°
    for _ in range(len(character_defs)):
        try:
            decision = st.session_state.facilitator.invoke({
                "input": f"{user_input}",
                "agent_history": st.session_state.agent_history
            })
            next_agent_name = decision["text"].strip()
            if next_agent_name not in st.session_state.agents:
                st.warning(f"âš ï¸ ç„¡åŠ¹ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŒ‡å®š: {next_agent_name}")
                break

            st.session_state.agent_history.append(next_agent_name)
            
            result = st.session_state.agents[next_agent_name].invoke({
                "chat_history": st.session_state.chat_history
            })

            response = json.loads(result["text"].replace("'", "\""))
            name = response.get("name")
            content = response.get("content", "ç„¡åŠ¹ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹")

            if content != "ç„¡åŠ¹ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹":
                st.session_state.chat_history.append({
                    "role": "assistant",
                    "name": next_agent_name[-1],
                    "content": f"{{'name': '{name}', 'content': '{content}'}}"
                })
            st.session_state.display_chat_history.append({
                "role": "assistant",
                "name": next_agent_name[-1],
                "content": content
            })
            with st.chat_message(next_agent_name[-1]):
                st.markdown(content)

        except Exception as e:
            # st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            # break
            error_message = traceback.format_exc()

            st.warning(f"âš ï¸ {next_agent_name}ã®ç™ºè¨€ã‚¨ãƒ©ãƒ¼: {error_message}")


