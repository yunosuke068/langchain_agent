import os
import traceback
import logging
from datetime import datetime
from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder
from langchain_core.messages import SystemMessage
from langchain_openai import AzureChatOpenAI
from langchain.agents import Tool, initialize_agent, AgentType
from langchain.chains.llm import LLMChain
from dataclasses import dataclass

# ========== LLM åˆæœŸåŒ– ==========
llm = AzureChatOpenAI(
    openai_api_version="2023-05-15",
    deployment_name="gpt-4o",
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    openai_api_key=os.getenv("AZURE_OPENAI_API_KEY"),
)

# ========== å…±é€šè„³ãƒ„ãƒ¼ãƒ«ç¾¤ ==========
class LLMBrainTool:
    name: str
    description: str
    prompt: str

    def __init__(self, name: str, description: str, prompt: str):
        self.name = name
        self.description = description
        self.prompt = prompt

    def __call__(self, input_text: str) -> str:
        prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content=f"ã‚ãªãŸã¯{self.name}ã§ã™ã€‚{self.prompt}"),
            HumanMessagePromptTemplate.from_template("{input}")
        ])
        chain = prompt | llm
        content = chain.invoke({"input": input_text}).content
        logging.info(f"Tool {self.name} invoked with input: {input_text}\nOutput: {content}")
        return content

brain_functions = {
    "æ„å›³æ¨è«–ãƒ„ãƒ¼ãƒ«": LLMBrainTool(
        name="æ„å›³æ¨è«–ãƒ„ãƒ¼ãƒ«",
        description="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã‚’æ¨è«–ã—ã€ç›®çš„ã‚’æ˜ç¢ºã«ã—ã¾ã™ã€‚",
        prompt="ã‚ãªãŸã®å½¹å‰²ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‚„ä¼šè©±å±¥æ­´ã‚’èª­ã¿å–ã‚Šã€ãã®äººãŒä½•ã‚’ç›®çš„ã¨ã—ã¦ãƒãƒ£ãƒƒãƒˆã‚’ã—ã¦ã„ã‚‹ã®ã‹ã‚’æ¨è«–ã™ã‚‹ã“ã¨ã§ã™ã€‚"
    ),
    "èª²é¡Œåˆ†è§£ãƒ„ãƒ¼ãƒ«": LLMBrainTool(
        name="èª²é¡Œåˆ†è§£ãƒ„ãƒ¼ãƒ«",
        description="å•é¡Œã‚’è¦ç´ ã«åˆ†è§£ã—ã€ã©ã®é †åºã‚„è¦³ç‚¹ã§è€ƒãˆã‚‹ã¹ãã‹ã‚’æ§‹é€ åŒ–ã—ã¾ã™ã€‚",
        prompt="ã‚ãªãŸã®å½¹å‰²ã¯ä¸ãˆã‚‰ã‚ŒãŸå•é¡Œã‚’è¤‡æ•°ã®è¦ç´ ã«åˆ†è§£ã—ã€ãã‚Œãã‚Œã‚’ã©ã®ã‚ˆã†ãªé †åºã‚„è¦–ç‚¹ã§è€ƒãˆã‚‹ã¹ãã‹ã‚’æ•´ç†ã™ã‚‹ã“ã¨ã§ã™ã€‚"
    ),
    "èƒŒæ™¯çŸ¥è­˜æ•´ç†ãƒ„ãƒ¼ãƒ«": LLMBrainTool(
        name="èƒŒæ™¯çŸ¥è­˜æ•´ç†ãƒ„ãƒ¼ãƒ«",
        description="è‡ªåˆ†ãŒæŒã¤çŸ¥è­˜ã®ä¸­ã‹ã‚‰é–¢ä¿‚ãŒã‚ã‚‹ã‚‚ã®ã‚’å–ã‚Šå‡ºã—ã€èª²é¡Œã«é–¢é€£ã¥ã‘ã¾ã™ã€‚",
        prompt="ã‚ãªãŸã®å½¹å‰²ã¯è‡ªåˆ†ã®çŸ¥è­˜ã®ä¸­ã‹ã‚‰ã€ä¸ãˆã‚‰ã‚ŒãŸèª²é¡Œã«é–¢é€£ã™ã‚‹èƒŒæ™¯çŸ¥è­˜ã‚’æŠ½å‡ºã—ã€ã©ã®ã‚ˆã†ã«é–¢ä¿‚ã™ã‚‹ã‹ã‚’æ•´ç†ã™ã‚‹ã“ã¨ã§ã™ã€‚"
    ),
    "ã‚¹ãƒ†ãƒƒãƒ—è¨ˆç”»ãƒ„ãƒ¼ãƒ«": LLMBrainTool(
        name="ã‚¹ãƒ†ãƒƒãƒ—è¨ˆç”»ãƒ„ãƒ¼ãƒ«",
        description="è§£æ±ºã¾ã§ã®æ‰‹é †ã‚„è­°è«–ã®æµã‚Œã‚’çµ„ã¿ç«‹ã¦ã€è¨ˆç”»ã‚’ç«‹ã¦ã¾ã™ã€‚",
        prompt="ã‚ãªãŸã®å½¹å‰²ã¯èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«å¿…è¦ãªã‚¹ãƒ†ãƒƒãƒ—ã‚’è¨ˆç”»ã—ã€è­°è«–ã‚„ä½œæ¥­ã®æµã‚Œã‚’æ˜ç¢ºã«ã™ã‚‹ã“ã¨ã§ã™ã€‚"
    ),
    "è‡ªå·±è©•ä¾¡ãƒ»çŸ›ç›¾æ¤œå‡ºãƒ„ãƒ¼ãƒ«": LLMBrainTool(
        name="è‡ªå·±è©•ä¾¡ãƒ»çŸ›ç›¾æ¤œå‡ºãƒ„ãƒ¼ãƒ«",
        description="è‡ªåˆ†ã®æ¨è«–ãƒ»ç­”ãˆã«çŸ›ç›¾ãŒãªã„ã‹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ã«å¿œã˜ã¦ä¿®æ­£ã‚’ä¿ƒã—ã¾ã™ã€‚",
        prompt="ã‚ãªãŸã®å½¹å‰²ã¯è‡ªåˆ†ã®æ¨è«–ã‚„å›ç­”å†…å®¹ã‚’å†è©•ä¾¡ã—ã€çŸ›ç›¾ã‚„èª¤ã‚ŠãŒãªã„ã‹ã‚’ç¢ºèªã—ã€å•é¡ŒãŒã‚ã‚Œã°ä¿®æ­£ã‚’ææ¡ˆã™ã‚‹ã“ã¨ã§ã™ã€‚"
    ),
    "æœ€çµ‚å‡ºåŠ›æ•´å½¢ãƒ„ãƒ¼ãƒ«": LLMBrainTool(
        name="æœ€çµ‚å‡ºåŠ›æ•´å½¢ãƒ„ãƒ¼ãƒ«",
        description="è‡ªåˆ†ã®ç­”ãˆã‚’ã€ç›¸æ‰‹ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ã«ã‚ã‹ã‚Šã‚„ã™ã„å½¢ã«ã¾ã¨ã‚ã€æ•´å½¢ã—ã¾ã™ã€‚",
        prompt="ã‚ãªãŸã®å½¹å‰²ã¯è‡ªåˆ†ãŒå‡ºã—ãŸçµè«–ã‚„ææ¡ˆã‚’ã€ç›¸æ‰‹ãŒç†è§£ã—ã‚„ã™ã„å½¢ã«ã¾ã¨ã‚ã€æ˜ç¢ºã«æ•´å½¢ã—ã¦ä¼ãˆã‚‹ã“ã¨ã§ã™ã€‚"
    )
}
brain_tools = []
for name, tool in brain_functions.items():
    brain_tools.append(
        Tool(
            name=name,
            func=lambda x: tool(x),
            description=tool.description
        )
    )

# ========== å„å°‚é–€å›ºæœ‰ãƒ„ãƒ¼ãƒ« ==========
def create_legal_tools(llm):
    # ä¾‹ï¼šæ³•å¾‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢
    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="ã‚ãªãŸã¯æ³•å¾‹å°‚é–€å®¶ã§ã™ã€‚è³ªå•ã«é–¢é€£ã™ã‚‹æ¡æ–‡ã‚„åˆ¤ä¾‹ã‚’å‚ç…§ã—ã¾ã™ã€‚"),
        HumanMessagePromptTemplate.from_template("{input}")
    ])
    chain = prompt | llm
    return [
        Tool(
            name="æ³•å¾‹DBæ¤œç´¢", 
            func=lambda x: chain.invoke({"input": x}).content, 
            description="æ³•å¾‹ã®æ¡æ–‡ã‚„åˆ¤ä¾‹ã‚’èª¿ã¹ã‚‹"
        )
    ]

def create_engineer_tools(llm):
    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="ã‚ãªãŸã¯ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚æŠ€è¡“ä»•æ§˜ã‚’è©•ä¾¡ã—ã€å®Ÿè£…æ¡ˆã‚’è€ƒãˆã¾ã™ã€‚"),
        HumanMessagePromptTemplate.from_template("{input}")
    ])
    chain = prompt | llm
    return [
        Tool(
            name="æŠ€è¡“ä»•æ§˜è©•ä¾¡", 
            func=lambda x: chain.invoke({"input": x}).content, 
            description="æŠ€è¡“çš„å®Ÿç¾æ€§ã‚„å·¥æ•°ã‚’è¦‹ç©ã‚‚ã‚‹"
        )
    ]

def create_common_sense_tools(llm):
    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="ã‚ãªãŸã¯ä¸€èˆ¬å¸¸è­˜ã«è©³ã—ã„å°‚é–€å®¶ã§ã™ã€‚ä¸–é–“çš„ãªæ„Ÿè¦šã‚„å¸¸è­˜ã‚’åæ˜ ã—ã¾ã™ã€‚"),
        HumanMessagePromptTemplate.from_template("{input}")
    ])
    chain = prompt | llm
    return [
        Tool(
            name="ä¸–é–“æ„Ÿè¦šåˆ†æ", 
            func=lambda x: chain.invoke({"input": x}).content, 
            description="ä¸€èˆ¬çš„ãªäººã€…ã®å—ã‘æ­¢ã‚æ–¹ã‚’äºˆæ¸¬ã™ã‚‹"
        )
    ]

# ========== å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ==========
def create_specialist_agent(name, system_msg, specific_tools):
    all_tools = brain_tools + specific_tools
    return initialize_agent(
        tools=all_tools,
        llm=llm,
        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
        verbose=True,
        system_message=system_msg
    )

legal_agent = create_specialist_agent("æ³•å¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", "ã‚ãªãŸã¯æ³•å¾‹ã®å°‚é–€å®¶ã§ã™ã€‚", create_legal_tools(llm))
engineer_agent = create_specialist_agent("ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", "ã‚ãªãŸã¯æŠ€è¡“ã®å°‚é–€å®¶ã§ã™ã€‚", create_engineer_tools(llm))
common_sense_agent = create_specialist_agent("ä¸€èˆ¬å¸¸è­˜ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", "ã‚ãªãŸã¯ä¸€èˆ¬å¸¸è­˜ã®å°‚é–€å®¶ã§ã™ã€‚", create_common_sense_tools(llm))

# ========== ãƒ­ã‚°è¨­å®š ==========
from langchain.callbacks.base import BaseCallbackHandler

class LogCallbackHandler(BaseCallbackHandler):
    def __init__(self, log_path):
        self.log_path = log_path

    def on_agent_action(self, action, **kwargs):
        with open(self.log_path, "a", encoding="utf-8") as f:
            f.write(f"<on_agent_action start> " + "=" * 20 + "\n")
            f.write(f"[Thought] {action.log}\n")
            f.write(f"[Action] {action.tool}\n")
            f.write(f"[Action Input] {action.tool_input}\n")
            f.write("-" * 40 + f" <on_agent_action end>" + "\n")

    def on_tool_end(self, output, **kwargs):
        with open(self.log_path, "a", encoding="utf-8") as f:
            f.write(f"[Observation] {output}\n")
            f.write("-" * 40 + "\n")

    def on_chain_end(self, outputs, **kwargs):
        with open(self.log_path, "a", encoding="utf-8") as f:
            f.write(f"[Final Output] {outputs}\n")
            f.write("=" * 60 + "\n")


# ========== å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‹•ä½œãƒ†ã‚¹ãƒˆ ==========
# user_question = "æ–°ã—ã„ç¤¾å“¡ç ”ä¿®åˆ¶åº¦ã‚’è¨­è¨ˆã™ã‚‹éš›ã®é‡è¦ãªæ³¨æ„ç‚¹ã¯ä½•ã§ã™ã‹ï¼Ÿ"
# datetime_str = datetime.now().strftime("%Y%m%d_%H%M%S")
# log_dir = "chat_logs"

# os.makedirs(log_dir, exist_ok=True)

# legal_result = legal_agent.invoke(input=user_question)
# engineer_result = engineer_agent.invoke(input=user_question)
# common_result = common_sense_agent.invoke(input=user_question,config={"callbacks": [LogCallbackHandler(f"{log_dir}/{datetime_str}_common_agent.txt")]})

# print("\n=== å„å°‚é–€å®¶ã®å›ç­” ===\n")
# print("æ³•å¾‹å°‚é–€å®¶ã®å›ç­”:", legal_result)
# print("ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å°‚é–€å®¶ã®å›ç­”:", engineer_result.content)
# print("ä¸€èˆ¬å¸¸è­˜å°‚é–€å®¶ã®å›ç­”:", common_result)


# ========== ãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ï¼ˆè­°é•·ï¼‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®šç¾©ã€€==========
def create_facilitator_prompt(chilsd_agent_names: list[str]):
    facilitator_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=f"ã‚ãªãŸã¯ãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¨éå»ã®ä¼šè©±å±¥æ­´ã‚’ã‚‚ã¨ã«ã€æ¬¡ã«ç™ºè¨€ã™ã¹ãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆ{'/'.join(chilsd_agent_names)}ï¼‰ã®åå‰ã ã‘ã‚’1ã¤è¿”ç­”ã—ã¦ãã ã•ã„ã€‚ä¼šè©±å±¥æ­´ã‚’è€ƒæ…®ã—ã€å½¹å‰²ã«åã‚ŠãŒå‡ºãªã„ã‚ˆã†ãƒãƒ©ãƒ³ã‚¹ã‚ˆãæŒ¯ã‚Šåˆ†ã‘ã¦ãã ã•ã„ã€‚"),
        MessagesPlaceholder(variable_name="chat_history"),
        HumanMessagePromptTemplate.from_template("{input}")
    ])
    return facilitator_prompt


# ========== ã‚·ã‚§ãƒ«ãƒ™ãƒ¼ã‚¹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ ==========
if __name__ == "__main__":
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æŒ‡å®š
    log_dir = "chat_logs"
    log_path = f"chat_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    os.makedirs(log_dir, exist_ok=True)
    log_path = os.path.join(log_dir, log_path)

    # ãƒã‚§ãƒ¼ãƒ³ç”Ÿæˆ
    agent_defs = {
        "æ³•å¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ": {
            "name": "æ³•å¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ",
            "description": "æ³•å¾‹ã®å°‚é–€å®¶ã¨ã—ã¦ã€æ³•å¾‹ã«é–¢ã™ã‚‹è³ªå•ã«ç­”ãˆã¾ã™ã€‚",
            "tool": legal_agent
        },
        "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ": {
            "name": "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ",
            "description": "æŠ€è¡“ã®å°‚é–€å®¶ã¨ã—ã¦ã€æŠ€è¡“çš„ãªè³ªå•ã«ç­”ãˆã¾ã™ã€‚",
            "tool": engineer_agent
        },
        "ä¸€èˆ¬å¸¸è­˜ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ": {
            "name": "ä¸€èˆ¬å¸¸è­˜ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ",
            "description": "ä¸€èˆ¬å¸¸è­˜ã®å°‚é–€å®¶ã¨ã—ã¦ã€ä¸–é–“çš„ãªæ„Ÿè¦šã‚„å¸¸è­˜ã‚’åæ˜ ã—ã¾ã™ã€‚",
            "tool": common_sense_agent
        }
    }
    # facilitator_chain = create_facilitator_agent_chain(llm, list(agent_defs.values()))
    facilitator_prompt = create_facilitator_prompt(list(agent_defs.keys()))

    # å±¥æ­´åˆæœŸåŒ–
    chat_history = []

    print("ğŸ™ï¸ ã‚­ãƒ£ãƒ©ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŸã¡ã¨ä¼šè©±ã—ã¾ã—ã‚‡ã†ï¼'exit'ã§çµ‚äº†ã—ã¾ã™ã€‚")

    while True:
        user_input = input("ğŸ§‘ ã‚ãªãŸ> ")
        if user_input.lower() == "exit":
            print("ğŸ‘‹ çµ‚äº†ã—ã¾ã™ã€‚")
            break

        chat_history.append({"role": "user", "content": user_input})
        # log_chat(log_path, "user", "ãƒ¦ãƒ¼ã‚¶ãƒ¼", user_input)

        # ä¼šè©±ã‚¿ãƒ¼ãƒ³æ•°
        num_turns = len(agent_defs) *1  # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒ2å›ç™ºè¨€ã™ã‚‹å ´åˆ
        for turn in range(num_turns):
            # æ¬¡ã«èª°ãŒè©±ã™ã‹ã‚’æ±ºã‚ã‚‹
            try:
                
                prompt_value = facilitator_prompt.invoke({
                    "input": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•",
                    "chat_history": chat_history
                })

                decision = llm.invoke(prompt_value)
                print(f"ğŸ—£ï¸ ãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ãƒ¼> {decision.content}")
                next_agent_name = decision.content.strip()
                if next_agent_name not in agent_defs:
                    print(f"âš ï¸ ç„¡åŠ¹ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŒ‡å®š: {next_agent_name}")
                    break
            except Exception as e:
                print(f"âš ï¸ ãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼: {e}\n\n{traceback.format_exc()}")
                break

            # é¸ã°ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ç™ºè¨€ã•ã›ã‚‹
            try:
                result = agent_defs[next_agent_name]["tool"].invoke(
                    f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€: {user_input}\néå»ã®ä¼šè©±å±¥æ­´: {chat_history}",
                )
                print(f"ğŸ¤– {next_agent_name}> {result['output']}")
                chat_history.append({"role": "assistant", "name": next_agent_name, "content": next_agent_name+": "+result["output"]})
                # log_chat(log_path, "assistant", next_agent_name, result["text"])
            except Exception as e:
                print(f"âš ï¸ {next_agent_name}ã®ç™ºè¨€ã‚¨ãƒ©ãƒ¼: {e}")
                break